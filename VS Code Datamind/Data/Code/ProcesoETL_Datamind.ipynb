{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Librerias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Liberia\n",
    "import pandas as pd\n",
    "\n",
    "#Permite buscar y recuperar una lista de nombres de archivos que coinciden con un patrón específico de nombre\n",
    "#de archivo en un directorio o en una jerarquía de directorios.\n",
    "import glob\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracción datos\n",
    "Obtener la lista de archivos que por pais y tipo de dato(sem - men):\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Mensual Historica\n",
    "\n",
    "# utilizamos la función glob para crear una lista de rutas de archivo que coinciden con el patrón *Chile Mensual*.csv\n",
    "# en el directorio path_chi_men. Esto nos da una lista de todas las rutas de archivo que cumplen con el patrón en el\n",
    "# directorio.\n",
    "\n",
    "#paht_data_historica= r'C:\\Users\\SSN0609\\OneDrive - Stanley Black & Decker\\Dashboards LAG\\Data Flow\\Datamind\\VS Code Datamind\\Data\\data Historico'\n",
    "paht_data_historica= r'C:\\Users\\SSN0609\\Documents\\Dashboards LAG PC LOCAL\\Data Flow\\Datamind\\VS Code Datamind\\Data\\data Historico'\n",
    "\n",
    "all_files_chi_men = glob.glob(paht_data_historica + \"/*Chile Mensual*.csv\")\n",
    "\n",
    "all_files_arg_men = glob.glob(paht_data_historica + \"/*Argentina Mensual*.csv\")\n",
    "\n",
    "all_files_per_men = glob.glob(paht_data_historica + \"/*Peru Mensual*.csv\")\n",
    "\n",
    "all_files_mex_men = glob.glob(paht_data_historica + \"/*Mexico Mensual*.csv\")\n",
    "\n",
    "#__________________________________________________\n",
    "\n",
    "#Data Semanal Historica\n",
    "all_files_chi_sem = glob.glob(paht_data_historica + \"/*Chile Semanal*.csv\")\n",
    "\n",
    "all_files_arg_sem = glob.glob(paht_data_historica + \"/*Argentina Semanal*.csv\")\n",
    "\n",
    "all_files_per_sem = glob.glob(paht_data_historica + \"/*Peru Semanal*.csv\")\n",
    "\n",
    "all_files_mex_sem = glob.glob(paht_data_historica + \"/*Mexico Semanal*.csv\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_files_chi_men)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Append listas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Leer cada archivo y agregarlos a una lista:\n",
    "ls_chi_men = []\n",
    "ls_mex_men = []\n",
    "ls_per_men = []\n",
    "ls_arg_men = []\n",
    "\n",
    "ls_chi_sem = []\n",
    "ls_mex_sem = []\n",
    "ls_per_sem = []\n",
    "ls_arg_sem = []\n",
    "\n",
    "# Se anexan los archivos en una sola lista\n",
    "\n",
    "for filename in all_files_chi_men:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_chi_men.append(df)\n",
    "\n",
    "for filename in all_files_arg_men:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_arg_men.append(df)\n",
    "\n",
    "for filename in all_files_per_men:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_per_men.append(df)\n",
    "\n",
    "for filename in all_files_mex_men:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_mex_men.append(df)\n",
    "\n",
    "\n",
    "\n",
    "for filename in all_files_chi_sem:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_chi_sem.append(df)\n",
    "\n",
    "for filename in all_files_arg_sem:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_arg_sem.append(df)\n",
    "\n",
    "for filename in all_files_per_sem:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_per_sem.append(df)\n",
    "\n",
    "for filename in all_files_mex_sem:\n",
    "    df = pd.read_csv(filename, index_col=None, header=0,dtype=str)\n",
    "    ls_mex_sem.append(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## lista a Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_chi_men = pd.concat(ls_chi_men, axis=0, ignore_index=True)\n",
    "df_arg_men = pd.concat(ls_arg_men, axis=0, ignore_index=True)\n",
    "df_per_men = pd.concat(ls_per_men, axis=0, ignore_index=True)\n",
    "df_mex_men = pd.concat(ls_mex_men, axis=0, ignore_index=True)\n",
    "\n",
    "df_chi_sem = pd.concat(ls_chi_sem, axis=0, ignore_index=True)\n",
    "df_arg_sem = pd.concat(ls_arg_sem, axis=0, ignore_index=True)\n",
    "df_per_sem = pd.concat(ls_per_sem, axis=0, ignore_index=True)\n",
    "df_mex_sem= pd.concat(ls_mex_sem, axis=0, ignore_index=True)\n",
    "\n",
    "# \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Se agrega columna \"tipo de datos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_chi_men['Tipo de dato'] ='men'\n",
    "df_mex_men['Tipo de dato'] ='men'\n",
    "df_arg_men['Tipo de dato'] ='men'\n",
    "df_per_men['Tipo de dato'] ='men'\n",
    "\n",
    "\n",
    "df_chi_sem['Tipo de dato'] ='sem'\n",
    "df_mex_sem['Tipo de dato'] ='sem'\n",
    "df_arg_sem['Tipo de dato'] ='sem'\n",
    "df_per_sem['Tipo de dato'] ='sem'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename col(mes -semana) -> Date\n",
    "Esto con el fin de poder concatener los dataframes y poder diferenciar el origen de la informacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "df_chi_men.rename(columns={'Mes':'Date'},inplace=True)\n",
    "df_chi_sem.rename(columns={'Semana':'Date'},inplace=True)\n",
    "\n",
    "df_arg_men.rename(columns={'Mes': 'Date'},inplace=True)\n",
    "df_arg_sem.rename(columns={'Semana':'Date'},inplace=True)\n",
    "\n",
    "df_per_men.rename(columns={'Mes':'Date'},inplace=True)\n",
    "df_per_sem.rename(columns={'Semana':'Date'},inplace=True)\n",
    "\n",
    "df_mex_men.rename(columns={'Mes':'Date'},inplace=True)\n",
    "df_mex_sem.rename(columns={'Semana':'Date'},inplace=True)\n",
    "\n",
    "#Concatenacion por pais\n",
    "\n",
    "df_chi =pd.concat([df_chi_men,df_chi_sem],axis=0,ignore_index=True)\n",
    "df_mex=pd.concat([df_mex_men,df_mex_sem],axis=0,ignore_index=True)\n",
    "df_per=pd.concat([df_per_men,df_per_sem],axis=0,ignore_index=True)\n",
    "df_arg=pd.concat([df_arg_men,df_arg_sem],axis=0,ignore_index=True)\n",
    "\n",
    "#se crea columna asignando pais\n",
    "df_chi['Country'] = 'Chile'\n",
    "df_per['Country'] = 'Peru'\n",
    "df_mex['Country'] = 'Mexico'\n",
    "df_arg['Country'] = df_arg['(L) Retailer'].apply(lambda x: 'Uruguay' if 'Uruguay' in x else 'Argentina')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hasta este punto se ha unificado todos los archivos de cada pais semanal y mensual en un solo dataframe.\n",
    "Se puede procecer a realizar el proceso de transformación correspondiente para cada país"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Alineacion de columnas\n",
    "Esto para poder concatenar todos los df en uno solo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Funcion que inserta columna vacia \n",
    "def crear_columnas_vacias(df, columnas, posiciones):\n",
    "    for col, pos in zip(columnas, posiciones):\n",
    "        df.insert(loc=pos, column=col, value='')\n",
    "\n",
    "#------------\n",
    "# Mexico        \n",
    "columnas_vacias = [\"vacia1\", \"vacia2\", \"vacia3\", \"vacia4\"]\n",
    "posiciones = [10, 12, 13, 14]\n",
    "crear_columnas_vacias(df_mex, columnas_vacias, posiciones)\n",
    "\n",
    "\n",
    "#------------\n",
    "# Peru\n",
    "columnas_vacias = [\"vacia1\", \"vacia2\", \"vacia3\", \"vacia4\", \"vacia5\", \"vacia6\", \"vacia7\", \"vacia8\"]\n",
    "posiciones = [4, 8, 9, 10, 12, 13, 14, 17]\n",
    "crear_columnas_vacias(df_per, columnas_vacias, posiciones)\n",
    "\n",
    "\n",
    "#------------\n",
    "# Argentina\n",
    "columnas_vacias = [\"vacia1\", \"vacia2\", \"vacia3\", \"vacia4\", \"vacia5\", \"vacia6\", \"vacia7\", \"vacia8\", \"vacia9\"]\n",
    "posiciones = [4, 8, 9, 10, 12, 13, 14, 17, 18]\n",
    "crear_columnas_vacias(df_arg, columnas_vacias, posiciones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_per=df_per.columns.to_list()\n",
    "col_arg=df_arg.columns.to_list()\n",
    "col_mex=df_mex.columns.to_list()\n",
    "col_chi = df_chi.columns.to_list()\n",
    "\n",
    "dict_renombres_per = {nombre_per: nombre_chi for nombre_per, nombre_chi in zip(col_per, col_chi)}\n",
    "dict_renombres_arg = {nombre_arg: nombre_chi for nombre_arg, nombre_chi in zip(col_arg, col_chi)}\n",
    "dict_renombres_mex = {nombre_mex: nombre_chi for nombre_mex, nombre_chi in zip(col_mex, col_chi)}\n",
    "\n",
    "\n",
    "\n",
    "df_per.rename(columns=dict_renombres_per, inplace=True)  # renombrar las columnas utilizando el diccionario\n",
    "df_mex.rename(columns=dict_renombres_mex, inplace=True)  # renombrar las columnas utilizando el diccionario\n",
    "df_arg.rename(columns=dict_renombres_arg, inplace=True)  # renombrar las columnas utilizando el diccionario\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## df_historico\n",
    "se concatenan los df_historico: df_mex df_arg df_per df_chi\n",
    "\n",
    "este contiene la data historica de todos los paises semanal y mensual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historico =pd.concat([df_chi,df_mex,df_arg,df_per],axis=0,ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tratamiento columnas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace tratamiento de las columnas que se usaran para el posterior proceso de tratamiento para mexico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nulos\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "df_historico['Date'] = df_historico['Date'].astype(str)\n",
    "\n",
    "df_historico['(L) Retailer'] =df_historico['(L) Retailer'].str.lower()\n",
    "df_historico['(L) Local'] = df_historico['(L) Local'].str.lower()\n",
    "df_historico['(I) SBU'] =df_historico['(I) SBU'].str.lower()\n",
    "\n",
    "df_historico.rename(columns={'(L) TIENDA FISICA /  ECOMMERCE':'canal_venta'},inplace=True)\n",
    "df_historico['canal_venta'] = df_historico['canal_venta'].str.lower().fillna('vacio').replace('', 'vacio')\n",
    "\n",
    "df_historico['(I) MARCA'] = df_historico['(I) MARCA'].astype(str).str.lower().fillna('vacio').replace('nan','vacio')\n",
    "df_historico['(E) Marca'] = df_historico['(E) Marca'].astype(str).str.lower().fillna('vacio').replace('nan','vacio')\n",
    "\n",
    "df_historico['(I) Código Producto Interno'] = df_historico['(I) Código Producto Interno'].astype(str).str.lower()\n",
    "df_historico['Tipo de dato'] = df_historico['Tipo de dato'].astype(str).str.lower()\n",
    "\n",
    "df_historico['Venta neta']=df_historico['Venta neta'].astype(float)\n",
    "df_historico['Venta bruta']=df_historico['Venta bruta'].astype(float)\n",
    "df_historico['Venta costo']=df_historico['Venta costo'].astype(float)\n",
    "df_historico['Unidades vendidas']=df_historico['Unidades vendidas'].astype(float)\n",
    "df_historico['Volumen vendido (Capacidad 1)']=df_historico['Volumen vendido (Capacidad 1)'].astype(float)\n",
    "df_historico['Precio Publico Estimado']=df_historico['Precio Publico Estimado'].str.replace(',', '').astype(float)\n",
    "\n",
    "#--- TRATAMIENTO NULOS\n",
    "\n",
    "#---STR\n",
    "def vacios_str(columna):\n",
    "  return columna.fillna('vacio').replace('', 'vacio')\n",
    "\n",
    "columnas_object = list(df_historico.select_dtypes(include=['object']).columns)\n",
    "\n",
    "for columna in columnas_object:\n",
    "  df_historico[columna] = vacios_str(df_historico[columna])\n",
    "\n",
    "#---FLOAT\n",
    "def vacios_float(columna):\n",
    "  return columna.fillna(0)\n",
    "columnas_float = list(df_historico.select_dtypes(include=['float']).columns)\n",
    "for columna in columnas_float:\n",
    "  df_historico[columna] = vacios_float(df_historico[columna])\n",
    "\n",
    "print(\"nulos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', '(L) Retailer', '(L) Local', '(L) Cadena', 'canal_venta',\n",
       "       '(I) SBU', '(I) MARCA', '(E) Marca', '(I) NPI', '(I) GPP Division',\n",
       "       '(I) GPP Division Cod.', '(I) GPP Category', '(I) GPP Category Cod.',\n",
       "       '(I) GPP Portfolio', '(I) GPP Portfolio Cod.', '(I) Producto Interno',\n",
       "       '(I) Código Producto Interno', '(I) OGSM Strategy',\n",
       "       '(I) CORD / CORDLESS / COMB / NEUM', 'Venta neta', 'Venta bruta',\n",
       "       'Venta costo', 'Unidades vendidas', 'Volumen vendido (Capacidad 1)',\n",
       "       'Precio Publico Estimado', 'Tipo de dato', 'Country'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historico.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se agrega una columna indice para el proceso de TDH Y Coppel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historico.reset_index(inplace=True)\n",
    "df_historico.rename(columns={'index': 'num_fila'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marcas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_marca= [  \n",
    " 'facom', 'iar expert', 'powers', 'troy-bilt', 'yard machine', 'no usar' ,\n",
    " 'stanley', 'dewalt', 'black+decker', 'irwin', 'proto','bostitch', 'fatmax', 'porter cable', \n",
    "'lenox', 'craftsman',   'gridest' \n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asignacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "df_historico['(I) MARCA'] = np.where((df_historico['(I) MARCA'] =='vacio') & (df_historico['(E) Marca'] != 'vacio'),\n",
    "                               df_historico['(E) Marca'],\n",
    "                               df_historico['(I) MARCA'])\n",
    "\n",
    "df_historico['(I) MARCA'] = df_historico['(I) MARCA'].replace('vacio', 'other')\n",
    "\n",
    "#-------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "correspondencias = {\n",
    "    'black+decker': ['b/d','black & de', 'black and decker', 'black&decker', 'black & decker', 'black+decker', 'black+deck', 'black + decker', 'b&d', 'b+d', 'black decker', 'black-d', 'black&deck'],\n",
    "    'dewalt': ['dewalt', 'de walt'],\n",
    "    'fatmax': ['stanley fatmax', 'fat max', 'fatmax'],\n",
    "    'bostitch': ['bosch', 'bostitch', 'bostitch office'],\n",
    "    'craftsman':['craftsman','craftman'],\n",
    "    'no usar': ['einhell','sierra','geo','samoa','smart','no usar']\n",
    "}\n",
    "\n",
    "df_historico['(I) MARCA'] = df_historico['(I) MARCA'].apply(lambda x: next((clave for clave, valor in correspondencias.items() if x in valor), x))\n",
    "df_historico['(I) MARCA'] =df_historico['(I) MARCA'].apply(lambda x:'other' if x not in lst_marca else x)\n",
    "df_historico['(I) MARCA'] =df_historico['(I) MARCA'].str.upper()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_historico['(I) MARCA'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SBU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historico['(I) SBU'] = df_historico['(I) SBU'].fillna('oth').replace(['',' ','no definido','vacio','nan'], 'oth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_historico['(I) SBU'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Canal Ecom-Tienda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_canal = 'internet|online|distancia|digital|virtual|ecommerce|e-com'\n",
    "lst_retailer = 'mercado libre|e-comm|ecommerce|mercadolibre|amazon'\n",
    "\n",
    "\n",
    "\n",
    "mask_retailer = df_historico['(L) Retailer'].str.contains(lst_retailer)\n",
    "mask_canal = df_historico['(L) Local'].str.contains(lst_canal)\n",
    "mask_ecom= (mask_retailer|mask_canal)\n",
    "\n",
    "df_historico.loc[mask_ecom, 'canal_venta'] = 'ecommerce'\n",
    "\n",
    "#mask_vacio = (df_historico['canal_venta'] == 'vacio')\n",
    "#df_historico.loc[mask_vacio, 'canal_venta'] = 'tienda'\n",
    "\n",
    "df_historico['canal_venta'] = df_historico['canal_venta'].replace(['vacio','moderno','tradicional','0','tienda'], 'store')\n",
    "df_historico['canal_venta'] = df_historico['canal_venta'].replace(['ecommerce','e-commerce'], 'e-commerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fin transformacion global\n",
    "Hasta este punto se ha conseguido unificar toda la informacion segun:\n",
    "    País\n",
    "    Año\n",
    "    tipo ( semanal - mensual)\n",
    "Con sus respectivos ajustes de:\n",
    "    Marca\n",
    "    SBU\n",
    "    Canal (tienda - ecommerce)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformacion Mexico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_historico['Date'] = df_historico['Date'].astype(str)\n",
    "#df_historico['(L) Retailer'] =df_historico['(L) Retailer'].str.lower()\n",
    "df_prueba = df_historico.loc[(df_historico['Country']=='Mexico')\n",
    "                    #& ((df_historico['(L) Retailer'] == 'the home depot') | (df_historico['(L) Retailer'] == 'the home depot e-comm') )\n",
    "                    \n",
    "                    & ((df_historico['Date'] =='202308') ) \n",
    "                    & (df_historico['Tipo de dato']== 'sem') \n",
    "                    #& (df_historico['(L) Local']== '1123 polanco')\n",
    "                    #& (df_historico['(I) Código Producto Interno']== 'DCK287D2-B3')\n",
    "                    ]\n",
    "#df_prueba= df_prueba.reset_index(drop=True)\n",
    "#df_prueba\n",
    "#Guardar el df_historico como archivo CSV en la ruta deseada\n",
    "ruta_archivo_csv = r'C:\\Users\\SSN0609\\OneDrive - Stanley Black & Decker\\Dashboards\\Datamind\\VS Code\\Data\\df_datamind_historico.csv'\n",
    "df_prueba.to_csv(ruta_archivo_csv, index=False)\n",
    "#pru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### THD\n",
    "Para el caso de thd sucede que datamind reporte thd store y thd ecommerce, pero en tdh store esta reportando la venta total( store + ecommerce), por lo cuál se debe restar la venta ecommercer a tdh store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea un df filtrado con TDH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_historico.loc[(df_historico['Country'] == 'Mexico')].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df_prueba = df_historico.loc[(df_historico['Country']=='Mexico')\n",
    "                    & ((df_historico['(L) Retailer'] == 'the home depot') | (df_historico['(L) Retailer'] == 'the home depot e-comm') )\n",
    "                    \n",
    "                    & ((df_historico['Date'] =='202318') ) \n",
    "                    & (df_historico['Tipo de dato']== 'sem') \n",
    "                    & (df_historico['(L) Local']== '1123 polanco')\n",
    "                    & (df_historico['(I) Código Producto Interno']== 'dck287d2-b3')\n",
    "                    ]\n",
    "df_prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(df_prueba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_thd = df_historico.loc[(df_historico['Country']=='Mexico')\n",
    "                    & ((df_historico['(L) Retailer'] == 'the home depot') | (df_historico['(L) Retailer'] == 'the home depot e-comm') )\n",
    "                    ]\n",
    "df_thd= df_thd.reset_index(drop=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "len(df_thd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se crea una columna concat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_thd['concat_thd'] = df_thd['Tipo de dato'] + df_thd['Date'] +df_thd['(L) Local']+ df_thd['(I) Código Producto Interno']+ df_thd['canal_venta']\n",
    "df_thd['concat_thd_ecom'] = df_thd['Tipo de dato'] + df_thd['Date'] +df_thd['(L) Local']+ df_thd['(I) Código Producto Interno']+ 'e-commerce'\n",
    "#df_thd['countif'] = df_thd.groupby('concat_thd_ecom')['concat_thd'].transform('count')\n",
    "counts = df_thd['concat_thd'].value_counts()\n",
    "df_thd['countif'] = df_thd['concat_thd_ecom'].map(counts)\n",
    "df_thd['concat_update'] = df_thd['Tipo de dato']+df_thd['Country'] + df_thd['Date'] +df_thd['(L) Retailer']\n",
    "df_thd['countif'] = df_thd['countif'].replace(np.nan, 0).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_thd['countif'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#contador= 0\n",
    "lst_concat= df_thd['concat_thd'].to_list()\n",
    "lst_concat_ecom= df_thd['concat_thd_ecom'].to_list()\n",
    "\n",
    "def actualizar_venta_neta(row, lst_concat):\n",
    "    if ((row['canal_venta'] == 'store') and (row['countif'] >= 1)):\n",
    "        row_index = lst_concat.index(row['concat_thd_ecom'])\n",
    "        row['Venta neta'] = row['Venta neta'] - df_thd.at[row_index, 'Venta neta']\n",
    "    else:\n",
    "        row['Venta neta'] = row['Venta neta']\n",
    "    return row\n",
    "\n",
    "df_thd = df_thd.apply(lambda row: actualizar_venta_neta(row, lst_concat) , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_historico['Date'] = df_historico['Date'].astype(str)\n",
    "\n",
    "df_prueba = df_thd.loc[(df_thd['Country']=='Mexico')\n",
    "                    & ((df_thd['(L) Retailer'] == 'the home depot') | (df_thd['(L) Retailer'] == 'the home depot e-comm') )\n",
    "                    \n",
    "                    & ((df_thd['Date'] =='202318') ) \n",
    "                    & (df_thd['Tipo de dato']== 'sem') \n",
    "                    & (df_thd['(L) Local']== '1123 polanco')\n",
    "                    & (df_thd['(I) Código Producto Interno']== 'dck287d2-b3')\n",
    "                    ]\n",
    "df_prueba= df_prueba.reset_index(drop=True)\n",
    "df_prueba\n",
    "#pru"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_thd['Venta neta']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(df_prueba.loc[:, ('canal_venta','Venta neta')])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actualizacion historico TDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thd.drop(['concat_thd','concat_thd_ecom', 'countif'],axis=1, inplace=True)\n",
    "\n",
    "df_merged = pd.merge(df_historico[['num_fila']], df_thd[['num_fila', 'Venta neta']], on='num_fila', how='left')\n",
    "df_historico['Venta neta'] = df_merged['Venta neta'].fillna(df_historico['Venta neta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#df_historico['Date'] = df_historico['Date'].astype(str)\n",
    "\n",
    "df_prueba = df_historico.loc[(df_historico['Country']=='Mexico')\n",
    "                    & ((df_historico['(L) Retailer'] == 'the home depot') | (df_historico['(L) Retailer'] == 'the home depot e-comm') )\n",
    "                    \n",
    "                    & ((df_historico['Date'] =='202318') ) \n",
    "                    & (df_historico['Tipo de dato']== 'sem') \n",
    "                    & (df_historico['(L) Local']== '1123 polanco')\n",
    "                    & (df_historico['(I) Código Producto Interno']== 'dck287d2-b3')\n",
    "                    ]\n",
    "#df_prueba= df_prueba.reset_index(drop=True)\n",
    "df_prueba\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(df_prueba.loc[:, ('canal_venta','Venta neta')])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_historico.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COPEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extraccion precios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ruta_coppel = r'C:\\Users\\SSN0609\\OneDrive - Stanley Black & Decker\\Dashboards LAG\\Data Flow\\Datamind\\VS Code Datamind\\Data\\Coppel\\precios_historico_coppel.csv'    \n",
    "    \n",
    "df_coppel_precios = pd.read_csv(ruta_coppel)\n",
    "df_coppel_precios['concat'] = df_coppel_precios['MODELO']+df_coppel_precios['P PUBLICO']\n",
    "df_coppel_precios.drop_duplicates(subset=['concat'],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df_prueba = df_historico.loc[(df_historico['Country']=='Mexico')\n",
    "                    & ((df_historico['(L) Retailer'] == 'coppel b')  )\n",
    "                    \n",
    "                    & ((df_historico['Date'] =='202210') ) \n",
    "                    & (df_historico['Tipo de dato']== 'sem') \n",
    "                    & (df_historico['(L) Local']== '2 canal digital coppel')\n",
    "                    & (df_historico['(I) Código Producto Interno']== 'd28730-b3')\n",
    "                    ]\n",
    "df_prueba= df_prueba.reset_index(drop=True)\n",
    "df_prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_coppel = df_historico.loc[(df_historico['Country']=='Mexico')\n",
    "                    & ((df_historico['(L) Retailer'] == 'coppel b')  )\n",
    "                    ]\n",
    "df_coppel= df_coppel.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "len(df_coppel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_coppel['Venta neta'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_coppel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir columnas a string y minúsculas\n",
    "\n",
    "df_coppel_precios['MODELO'] = df_coppel_precios['MODELO'].astype(str).str.lower()\n",
    "df_coppel_precios['año'] = df_coppel_precios['año'].astype(str)\n",
    "\n",
    "\n",
    "# Crear nuevas columnas\n",
    "df_coppel['year_modelo'] = df_coppel['Date'].str[:4] + df_coppel['(I) Código Producto Interno']\n",
    "df_coppel_precios['year_modelo'] = df_coppel_precios['año'] + df_coppel_precios['MODELO']\n",
    "df_coppel_precios = df_coppel_precios.drop_duplicates(subset='year_modelo')\n",
    "\n",
    "\n",
    "# Realizar la búsqueda\n",
    "df_coppel = df_coppel.merge(df_coppel_precios[['year_modelo', 'P PUBLICO']], on='year_modelo', how='left')\n",
    "\n",
    "\n",
    "# Convertir precios a float64\n",
    "df_coppel['P PUBLICO'] = df_coppel['P PUBLICO'].str.replace(',', '').astype(np.float64)\n",
    "\n",
    "\n",
    "# Calcular la venta neta\n",
    "df_coppel['Venta neta'] = df_coppel['Unidades vendidas'] * df_coppel['P PUBLICO']\n",
    "\n",
    "\n",
    "#elimino columna para poder concatener al df_historico\n",
    "df_coppel.drop(['year_modelo', 'P PUBLICO'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_coppel['Venta neta'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_coppel.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "df_coppel2 = df_coppel.loc[(df_coppel['Country']=='Mexico')\n",
    "                    & ((df_coppel['(L) Retailer'] == 'coppel b')  )\n",
    "                    \n",
    "                    & ((df_coppel['Date'] =='202210') ) \n",
    "                    & (df_coppel['Tipo de dato']== 'sem') \n",
    "                    #& (df_coppel['(L) Local']== '2 canal digital coppel')\n",
    "                    & (df_coppel['(I) Código Producto Interno']== 'd28730-b3')\n",
    "                    ]\n",
    "df_coppel2= df_coppel2.reset_index(drop=True)\n",
    "df_coppel2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged = pd.merge(df_historico[['num_fila']], df_coppel[['num_fila', 'Venta neta']], on='num_fila', how='left')\n",
    "df_historico['Venta neta'] = df_merged['Venta neta'].fillna(df_historico['Venta neta'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Columna update\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historico['concat_update'] = df_historico['Country']+df_historico['Tipo de dato']+df_historico['Date']\n",
    "df_historico['concat_update'] = df_historico['concat_update'].str.lower().str.strip()\n",
    "\n",
    "df_historico['concat_update_meli_amz'] = df_historico['Country']+df_historico['(L) Retailer']+df_historico['Tipo de dato']+df_historico['Date']\n",
    "df_historico['concat_update'] = df_historico['concat_update'].str.lower().str.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "from isoweek import Week\n",
    "\n",
    "from datetime import datetime as dt\n",
    "def get_date_from_year_week(year_week):\n",
    "    year = int(year_week[:4])\n",
    "    week = int(year_week[4:])\n",
    "    # Obtener la fecha del primer día de la semana\n",
    "    first_day_of_week = Week(year, week).monday()\n",
    "    # Agregar 1 día para obtener la fecha del lunes de esa semana\n",
    "    #date = first_day_of_week + timedelta(days=1)\n",
    "    # Formatear la fecha en el formato deseado\n",
    "    return first_day_of_week.strftime('%m-%d-%Y')\n",
    "\n",
    "def get_date_from_year_month(year_month):\n",
    "    year = int(year_month[:4])\n",
    "    month = int(year_month[4:])\n",
    "    # Obtener la fecha del primer día del mes\n",
    "    date = datetime(year, month, 1)\n",
    "    # Formatear la fecha en el formato deseado\n",
    "    return date.strftime('%m-%d-%Y')\n",
    "\n",
    "\n",
    "# Aplicar las funciones lambda al dataframe\n",
    "df_historico['Fecha']=''\n",
    "df_historico = df_historico.fillna('')\n",
    "df_historico.loc[(df_historico['Tipo de dato'] == 'sem') & (df_historico['Fecha'] == ''), 'Fecha'] = df_historico.loc[df_historico['Tipo de dato'] == 'sem', 'Date'].apply(get_date_from_year_week)\n",
    "df_historico.loc[(df_historico['Tipo de dato'] == 'men') & (df_historico['Fecha'] == ''), 'Fecha'] = df_historico.loc[df_historico['Tipo de dato'] == 'men', 'Date'].apply(get_date_from_year_month)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_fila</th>\n",
       "      <th>Date</th>\n",
       "      <th>(L) Retailer</th>\n",
       "      <th>(L) Local</th>\n",
       "      <th>(L) Cadena</th>\n",
       "      <th>canal_venta</th>\n",
       "      <th>(I) SBU</th>\n",
       "      <th>(I) MARCA</th>\n",
       "      <th>(E) Marca</th>\n",
       "      <th>(I) NPI</th>\n",
       "      <th>...</th>\n",
       "      <th>Venta bruta</th>\n",
       "      <th>Venta costo</th>\n",
       "      <th>Unidades vendidas</th>\n",
       "      <th>Volumen vendido (Capacidad 1)</th>\n",
       "      <th>Precio Publico Estimado</th>\n",
       "      <th>Tipo de dato</th>\n",
       "      <th>Country</th>\n",
       "      <th>concat_update</th>\n",
       "      <th>concat_update_meli_amz</th>\n",
       "      <th>Fecha</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9082081</th>\n",
       "      <td>9082081</td>\n",
       "      <td>202252</td>\n",
       "      <td>amazon mx</td>\n",
       "      <td>1 amazon mexico</td>\n",
       "      <td>Amazon MX</td>\n",
       "      <td>ecommerce</td>\n",
       "      <td>cptc</td>\n",
       "      <td>BLACK+DECKER</td>\n",
       "      <td>vacio</td>\n",
       "      <td>SST1801-B3</td>\n",
       "      <td>...</td>\n",
       "      <td>7205.1800</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3602.590000</td>\n",
       "      <td>sem</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mexicosem202252</td>\n",
       "      <td>Mexicoamazon mxsem202252</td>\n",
       "      <td>12-26-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082143</th>\n",
       "      <td>9082143</td>\n",
       "      <td>202252</td>\n",
       "      <td>sears</td>\n",
       "      <td>229 tuxtla gutierrez</td>\n",
       "      <td>Sears</td>\n",
       "      <td>tienda</td>\n",
       "      <td>hts</td>\n",
       "      <td>CRAFTSMAN</td>\n",
       "      <td>craftsman</td>\n",
       "      <td>BASICO BIG TICKET</td>\n",
       "      <td>...</td>\n",
       "      <td>59.2200</td>\n",
       "      <td>36.67</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>59.220000</td>\n",
       "      <td>sem</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mexicosem202252</td>\n",
       "      <td>Mexicosearssem202252</td>\n",
       "      <td>12-26-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082161</th>\n",
       "      <td>9082161</td>\n",
       "      <td>202252</td>\n",
       "      <td>sears</td>\n",
       "      <td>51 rio</td>\n",
       "      <td>Sears</td>\n",
       "      <td>tienda</td>\n",
       "      <td>hts</td>\n",
       "      <td>CRAFTSMAN</td>\n",
       "      <td>craftsman</td>\n",
       "      <td>BASICO BIG TICKET</td>\n",
       "      <td>...</td>\n",
       "      <td>692.2800</td>\n",
       "      <td>408.34</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>692.280000</td>\n",
       "      <td>sem</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mexicosem202252</td>\n",
       "      <td>Mexicosearssem202252</td>\n",
       "      <td>12-26-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082318</th>\n",
       "      <td>9082318</td>\n",
       "      <td>202252</td>\n",
       "      <td>the home depot</td>\n",
       "      <td>8748 mixcoac</td>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>tienda</td>\n",
       "      <td>hts</td>\n",
       "      <td>DEWALT</td>\n",
       "      <td>vacio</td>\n",
       "      <td>DWHT34192-B3</td>\n",
       "      <td>...</td>\n",
       "      <td>533.9712</td>\n",
       "      <td>319.97</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>263.040004</td>\n",
       "      <td>sem</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mexicosem202252</td>\n",
       "      <td>Mexicothe home depotsem202252</td>\n",
       "      <td>12-26-2022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9082373</th>\n",
       "      <td>9082373</td>\n",
       "      <td>202252</td>\n",
       "      <td>the home depot</td>\n",
       "      <td>8636 tlaquepaque</td>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>tienda</td>\n",
       "      <td>ohp</td>\n",
       "      <td>BLACK+DECKER</td>\n",
       "      <td>vacio</td>\n",
       "      <td>RS-300</td>\n",
       "      <td>...</td>\n",
       "      <td>145.9976</td>\n",
       "      <td>87.99</td>\n",
       "      <td>2.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>71.920001</td>\n",
       "      <td>sem</td>\n",
       "      <td>Mexico</td>\n",
       "      <td>mexicosem202252</td>\n",
       "      <td>Mexicothe home depotsem202252</td>\n",
       "      <td>12-26-2022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         num_fila    Date    (L) Retailer             (L) Local  \\\n",
       "9082081   9082081  202252       amazon mx       1 amazon mexico   \n",
       "9082143   9082143  202252           sears  229 tuxtla gutierrez   \n",
       "9082161   9082161  202252           sears                51 rio   \n",
       "9082318   9082318  202252  the home depot          8748 mixcoac   \n",
       "9082373   9082373  202252  the home depot      8636 tlaquepaque   \n",
       "\n",
       "             (L) Cadena canal_venta (I) SBU     (I) MARCA  (E) Marca  \\\n",
       "9082081       Amazon MX   ecommerce    cptc  BLACK+DECKER      vacio   \n",
       "9082143           Sears      tienda     hts     CRAFTSMAN  craftsman   \n",
       "9082161           Sears      tienda     hts     CRAFTSMAN  craftsman   \n",
       "9082318  The Home Depot      tienda     hts        DEWALT      vacio   \n",
       "9082373  The Home Depot      tienda     ohp  BLACK+DECKER      vacio   \n",
       "\n",
       "                   (I) NPI  ... Venta bruta Venta costo Unidades vendidas  \\\n",
       "9082081         SST1801-B3  ...   7205.1800        0.00              2.00   \n",
       "9082143  BASICO BIG TICKET  ...     59.2200       36.67              1.00   \n",
       "9082161  BASICO BIG TICKET  ...    692.2800      408.34              1.00   \n",
       "9082318       DWHT34192-B3  ...    533.9712      319.97              2.03   \n",
       "9082373             RS-300  ...    145.9976       87.99              2.03   \n",
       "\n",
       "        Volumen vendido (Capacidad 1) Precio Publico Estimado Tipo de dato  \\\n",
       "9082081                           0.0             3602.590000          sem   \n",
       "9082143                           1.0               59.220000          sem   \n",
       "9082161                           0.0              692.280000          sem   \n",
       "9082318                           0.0              263.040004          sem   \n",
       "9082373                           0.0               71.920001          sem   \n",
       "\n",
       "        Country    concat_update         concat_update_meli_amz       Fecha  \n",
       "9082081  Mexico  mexicosem202252       Mexicoamazon mxsem202252  12-26-2022  \n",
       "9082143  Mexico  mexicosem202252           Mexicosearssem202252  12-26-2022  \n",
       "9082161  Mexico  mexicosem202252           Mexicosearssem202252  12-26-2022  \n",
       "9082318  Mexico  mexicosem202252  Mexicothe home depotsem202252  12-26-2022  \n",
       "9082373  Mexico  mexicosem202252  Mexicothe home depotsem202252  12-26-2022  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historico[(df_historico['Tipo de dato'] == 'sem') & \n",
    "                           (df_historico['Date'].str.startswith('202252'))].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Chile', 'Mexico', 'Argentina', 'Uruguay', 'Peru'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historico['Country'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_historico['Holder']=''\n",
    "notacion_holder = {\n",
    "    'Mercado Libre': ['mercadolibre','mercado libre', 'mercado libre multivende', 'mercado libre spiral', 'mercado libre spiral ar'],\n",
    "    'Sodimac': ['sodimac', 'sodimac mexico', 'sodimac argentina', 'sodimac uruguay', 'sodimac peru'],\n",
    "    'Amazon': ['amazon mx'],\n",
    "    'Walmart': ['walmart', 'walmart mexico', 'walmart argentina'],\n",
    "    'Coppel': ['coppel b'],\n",
    "    'The Home Depot': ['the home depot e-comm', 'the home depot'],\n",
    "    'Easy': ['easy argentina'],\n",
    "    'Carrefour':['carrefour argentina']\n",
    "}\n",
    "notacion_pais = {\n",
    "    'Mexico': 'MX',\n",
    "    'Chile': 'CH',\n",
    "    'Argentina': 'AR',\n",
    "    'Uruguay': 'URU',\n",
    "    'Peru': 'PE'\n",
    "}\n",
    "\n",
    "notacion_holder_invertido = {value: key for key, values in notacion_holder.items() for value in values}\n",
    "\n",
    "lst = ['mercado libre', 'sodimac', 'walmart', 'the home depot', 'easy', 'amazon']\n",
    "\n",
    "\n",
    "def holder(row):\n",
    "    pais = notacion_pais.get(row['Country'], row['Country'])\n",
    "    retailer = notacion_holder_invertido.get(row['(L) Retailer'].lower(), row['(L) Retailer'])\n",
    "    \n",
    "    local = row['(L) Local'].lower()\n",
    "    retailer = retailer.lower()\n",
    "\n",
    "    if pais == 'CH' and retailer == 'mercado libre' and local in ['fcom fcom', 'fcom']:\n",
    "        retailer = 'falabella'\n",
    "    elif pais == 'CH' and retailer == 'mercado libre' and local in[ 'paris paris','paris']:\n",
    "        retailer = 'paris'\n",
    "\n",
    "    if retailer in lst:\n",
    "        return retailer + ' ' + pais\n",
    "    else:\n",
    "        return retailer\n",
    "df_historico['Holder'] = df_historico.apply(holder, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['construmart', 'easy CH', 'ferretek', 'imperial',\n",
       "       'mercado libre CH', 'mts', 'paris', 'sodimac CH', 'walmart CH',\n",
       "       'autoplanet', 'ausin', 'falabella', 'imperial manual',\n",
       "       'establecimientos maipo', 'pernos kim', 'villar hermanos',\n",
       "       'oviedo', 'amazon MX', 'chedraui', 'coppel', 'ferremayoreo',\n",
       "       'grainger', 'liverpool', 'officemax', \"sam's club\", 'sears',\n",
       "       'sodimac MX', 'the home depot MX', 'walmart MX',\n",
       "       'mercado libre MX', 'office depot', 'toledo', 'la comer',\n",
       "       'soriana', 'easy AR', 'la anonima', 'sodimac AR', 'walmart AR',\n",
       "       'mercado libre AR', 'carrefour', 'sodimac URU', 'promart',\n",
       "       'sodimac PE'], dtype=object)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historico['Holder'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ventas USD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_fila', 'Date', '(L) Retailer', '(L) Local', '(L) Cadena',\n",
       "       'canal_venta', '(I) SBU', '(I) MARCA', '(E) Marca', '(I) NPI',\n",
       "       '(I) GPP Division', '(I) GPP Division Cod.', '(I) GPP Category',\n",
       "       '(I) GPP Category Cod.', '(I) GPP Portfolio', '(I) GPP Portfolio Cod.',\n",
       "       '(I) Producto Interno', '(I) Código Producto Interno',\n",
       "       '(I) OGSM Strategy', '(I) CORD / CORDLESS / COMB / NEUM', 'Venta neta',\n",
       "       'Venta bruta', 'Venta costo', 'Unidades vendidas',\n",
       "       'Volumen vendido (Capacidad 1)', 'Precio Publico Estimado',\n",
       "       'Tipo de dato', 'Country', 'concat_update', 'concat_update_meli_amz',\n",
       "       'Fecha', 'Holder'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historico.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_fx_rate = r'C:\\Users\\SSN0609\\OneDrive - Stanley Black & Decker\\Dashboards LAG\\Data Flow\\Shares Information for Projects\\FX Rate\\FX_Rate.xlsx'\n",
    "\n",
    "df_historico['fecha_my'] = pd.to_datetime(df_historico['Fecha']).dt.strftime('%m%Y')\n",
    "\n",
    "df_fx_rate = pd.read_excel(ruta_fx_rate)\n",
    "df_fx_rate.drop_duplicates(subset=['Fecha', 'Country'], inplace=True) # Agregar inplace=True para modificar el dataframe original\n",
    "df_fx_rate['Country']= df_fx_rate['Country'].apply(lambda x: 'Uruguay' if x=='PUB' else x)\n",
    "df_fx_rate['Fecha'] = pd.to_datetime(df_fx_rate['Fecha'])\n",
    "df_fx_rate['fecha_my'] = df_fx_rate['Fecha'].dt.strftime('%m%Y')\n",
    "df_fx_rate = df_fx_rate[df_fx_rate['Country'].isin(df_historico['Country']) \n",
    "                          & df_fx_rate['fecha_my'].isin(df_historico['fecha_my'])]\n",
    "\n",
    "df_historico = pd.merge(df_historico, df_fx_rate[['fecha_my', 'Country', 'Adjusted Rate']], on=[\"fecha_my\", \"Country\"], how='left')\n",
    "try:\n",
    "    df_historico['Venta_neta_usd'] = df_historico['Venta neta'] / df_historico['Adjusted Rate']\n",
    "except:\n",
    "    df_historico['Venta_neta_usd'] = df_historico['Venta neta']\n",
    "\n",
    "df_historico['Venta_neta_usd']=df_historico['Venta_neta_usd'].fillna(0)\n",
    "df_historico.drop(['fecha_my', 'Adjusted Rate'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['num_fila', 'Date', '(L) Retailer', '(L) Local', '(L) Cadena',\n",
       "       'canal_venta', '(I) SBU', '(I) MARCA', '(E) Marca', '(I) NPI',\n",
       "       '(I) GPP Division', '(I) GPP Division Cod.', '(I) GPP Category',\n",
       "       '(I) GPP Category Cod.', '(I) GPP Portfolio', '(I) GPP Portfolio Cod.',\n",
       "       '(I) Producto Interno', '(I) Código Producto Interno',\n",
       "       '(I) OGSM Strategy', '(I) CORD / CORDLESS / COMB / NEUM', 'Venta neta',\n",
       "       'Venta bruta', 'Venta costo', 'Unidades vendidas',\n",
       "       'Volumen vendido (Capacidad 1)', 'Precio Publico Estimado',\n",
       "       'Tipo de dato', 'Country', 'concat_update', 'concat_update_meli_amz',\n",
       "       'Fecha', 'Holder', 'Venta_neta_usd'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_historico.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Guardar df_historico como df_datamind_historico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# guardar archivo en el pc local\n",
    "ruta_local_archivo_csv = r'C:\\Users\\SSN0609\\Documents\\Dashboards LAG PC LOCAL\\Data Flow\\Datamind\\Data Flow\\df_datamind_historico.csv'\n",
    "df_historico.to_csv(ruta_local_archivo_csv, index=False)\n",
    "\n",
    "\n",
    "# Guardar archivo en el drive\n",
    "#ruta_drive_archivo_csv = r'C:\\Users\\SSN0609\\OneDrive - Stanley Black & Decker\\Dashboards LAG\\Data Flow\\Datamind\\Data Flow\\df_datamind_historico.csv'\n",
    "#df_historico.to_csv(ruta_drive_archivo_csv, index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
